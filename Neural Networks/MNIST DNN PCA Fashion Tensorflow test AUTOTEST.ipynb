{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4e27af",
   "metadata": {},
   "source": [
    "# Epoch test\n",
    "This script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0d376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:40.983219Z",
     "start_time": "2022-12-19T08:46:40.897012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funky shit\n",
    "import os\n",
    "import csv\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu/libcudart.so.11.0'\n",
    "from PIL import Image,ImageOps\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e16db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:45.908983Z",
     "start_time": "2022-12-19T08:46:45.902850Z"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf57cc",
   "metadata": {},
   "source": [
    "## Import MNIST Fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda70a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T12:32:38.819320Z",
     "start_time": "2022-12-12T12:32:38.289437Z"
    }
   },
   "outputs": [],
   "source": [
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# # Setup labels as vector outputs rather than digit value\n",
    "# train_labelsVektor = np.zeros((10, len(train_labels)))\n",
    "# for i in range(len(train_labels)):\n",
    "#     for j in range(10):\n",
    "#         if train_labels[i] == j:\n",
    "#             train_labelsVektor[j, i] += 1\n",
    "# train_labelsVektor = np.transpose(train_labelsVektor)\n",
    "\n",
    "# test_labelsVektor = np.zeros((10, len(test_labels)))\n",
    "# for i in range(len(test_labels)):\n",
    "#     for j in range(10):\n",
    "#         if test_labels[i] == j:\n",
    "#             test_labelsVektor[j, i] += 1\n",
    "# test_labelsVektor = np.transpose(test_labelsVektor)\n",
    "\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# # Normalize\n",
    "# train_images = train_images / 255.0\n",
    "# test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362628b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:47:52.856702Z",
     "start_time": "2022-12-19T08:47:52.840683Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_reduced_data(keepClasses: list, qubitCount):\n",
    "    \"\"\"\n",
    "    Takes a list of classes to keep and returns reduced mnist dataset.\n",
    "    Loops over full data and appends to list if the class is in keepClasses.\n",
    "    A list is used for performance reasons, since Numpy Append copies the entire array\n",
    "    every time. The lists are cast to numpy array before returning.\n",
    "    \n",
    "    :param list keepClasses: List of ints.\n",
    "    :return: returns two tuples. One with train data and one with test data.\n",
    "    \"\"\"\n",
    "    transDict = {}\n",
    "    for i in range(len(keepClasses)):\n",
    "        transDict[keepClasses[i]] = i\n",
    "    print(transDict)\n",
    "    \n",
    "    \n",
    "    #fashion_mnist = fashion_mnist\n",
    "    (train_images_full, train_labels_full), (test_images_full, test_labels_full) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    \n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    print(\"Loading train data\")\n",
    "    for i in tqdm(list(range(len(train_labels_full)))):\n",
    "        if train_labels_full[i] in keepClasses:\n",
    "            train_labels.append(transDict[train_labels_full[i]])\n",
    "            train_images.append(train_images_full[i])\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    print(\"Loading test data\")\n",
    "    for i in tqdm(list(range(len(test_labels_full)))):\n",
    "        if test_labels_full[i] in keepClasses:\n",
    "            test_labels.append(transDict[test_labels_full[i]])\n",
    "            test_images.append(test_images_full[i])\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    \n",
    "    # Setup labels as vector outputs rather than digit value\n",
    "    train_labelsVektor = np.zeros((qubitCount, len(train_labels)))\n",
    "    for i in range(len(train_labels)):\n",
    "        for j in range(len(keepClasses)):\n",
    "            if train_labels[i] == j:\n",
    "                train_labelsVektor[j, i] += 1\n",
    "    train_labelsVektor = np.transpose(train_labelsVektor)\n",
    "\n",
    "    test_labelsVektor = np.zeros((qubitCount, len(test_labels)))\n",
    "    for i in range(len(test_labels)):\n",
    "        for j in range(len(keepClasses)):\n",
    "            if test_labels[i] == j:\n",
    "                test_labelsVektor[j, i] += 1\n",
    "    test_labelsVektor = np.transpose(test_labelsVektor)\n",
    "    \n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return (train_images, train_labelsVektor), (test_images, test_labelsVektor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadf1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:54.386029Z",
     "start_time": "2022-12-19T08:46:54.375674Z"
    }
   },
   "outputs": [],
   "source": [
    "def nDimPCA(dimOut, data):\n",
    "    \"\"\"\n",
    "    Applies the PCA with to training data \n",
    "    \n",
    "    :param int dimOut: Dimension of the output data\n",
    "    :param np.array data: Matrices containing the training data\n",
    "    :return: returns the reduced training data now in reduced dimension\n",
    "    \"\"\"\n",
    "    #Normalize data\n",
    "    #Flatten input data\n",
    "    data = data.reshape([np.size(data,0),np.size(data,1)*np.size(data,2)])\n",
    "    #Mean\n",
    "    mu = np.mean(data, axis = 0)\n",
    "    mu = mu.reshape([np.size(mu,0),1])\n",
    "    #covariance\n",
    "    data = np.transpose(data)\n",
    "    sigma = np.cov(data-mu)\n",
    "    #SVD\n",
    "    U, S, V = np.linalg.svd(sigma)\n",
    "    #V reduced\n",
    "    VReduced = V[0:dimOut,0:]\n",
    "    #output reduced data\n",
    "    out = np.dot(VReduced,(data-mu))\n",
    "    return np.transpose(out),mu,VReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe22719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:55.899735Z",
     "start_time": "2022-12-19T08:46:55.891412Z"
    }
   },
   "outputs": [],
   "source": [
    "def PCAOnTest(VReduced, mu, data):\n",
    "    \"\"\"\n",
    "    Applies the PCA to test data\n",
    "    \n",
    "    :param np.array VReduced: Eigenvectors for the PCA\n",
    "    :param np.array mu: Vector containing the mean values \n",
    "    :param np.array data: Matrices containing the test data\n",
    "    :return: returns the reduced test data now in the same dimension as the training data\n",
    "    \"\"\"\n",
    "    data = data.reshape([np.size(data,0),np.size(data,1)*np.size(data,2)])\n",
    "    data = np.transpose(data)\n",
    "    out = np.dot(VReduced,(data-mu))\n",
    "    \n",
    "    \n",
    "    return np.transpose(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292891c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:57.023134Z",
     "start_time": "2022-12-19T08:46:57.015884Z"
    }
   },
   "outputs": [],
   "source": [
    "def generateModel(nodes, ActivationFunctions, inputShape, outputShape):\n",
    "    model = tf.keras.Sequential()\n",
    "    #model.add(tf.keras.layers.InputLayer(batch_size=32))\n",
    "    for i in range(len(nodes)):\n",
    "        model.add(tf.keras.layers.Dense(nodes[i], activation=activationFunctions))\n",
    "    model.add(tf.keras.layers.Dense(outputShape, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fa113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:58.485131Z",
     "start_time": "2022-12-19T08:46:58.478608Z"
    }
   },
   "outputs": [],
   "source": [
    "def compileModel(model):\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d501c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:46:59.505189Z",
     "start_time": "2022-12-19T08:46:59.497264Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModel(model, epochs):\n",
    "    trainAccuracy = np.zeros(epochs)\n",
    "    testAccuracy = np.zeros(epochs)\n",
    "    for i in range(epochs):\n",
    "        print('Epoch iteration: ' + str(i+1))\n",
    "        with tf.device('/GPU:0'):\n",
    "            history = model.fit(train_images_red, train_labelsVektor, epochs=1)\n",
    "        trainAccuracy[i] = history.history[\"accuracy\"][0]\n",
    "        test_loss, test_acc = model.evaluate(test_images_red,  test_labelsVektor)\n",
    "        testAccuracy[i] = test_acc\n",
    "    return trainAccuracy, testAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3bcff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:47:00.843435Z",
     "start_time": "2022-12-19T08:47:00.833547Z"
    }
   },
   "outputs": [],
   "source": [
    "def writeToCSV(nodes, dimSet, activationFunction, trainAccuracy, testAccuracy, classes):\n",
    "    with open('./Verysmallnetwork/' + 'PCA' + str(dimSet) + 'NODES' + str(nodes) + 'classes' + str(len(classes)) +'.csv', 'w', encoding='UTF8') as f: #/PCA_DNN_test\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Layers: ' + str(len(nodes))])\n",
    "        writer.writerow(['Nodes: ' + str(nodes)])\n",
    "        writer.writerow(['PCA dim: ' + str(dimSet)])\n",
    "        writer.writerow(['Activation function: ' + activationFunction])\n",
    "        writer.writerow(['Training accuracy', 'Test accuracy'])\n",
    "        writer.writerow(['Classes: ' + str(classes)])\n",
    "        for i in range(len(trainAccuracy)):\n",
    "            writer.writerow([trainAccuracy[i], testAccuracy[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115e39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T18:01:22.998087Z",
     "start_time": "2022-11-15T18:01:22.989844Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c56d19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T08:49:21.294468Z",
     "start_time": "2022-12-19T08:47:55.601056Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "(train_images, train_labelsVektor), (test_images, test_labelsVektor) = load_reduced_data(classes, len(classes))\n",
    "\n",
    "# Neural network setup\n",
    "nodes = [[1],[2],[3],[4],[5],[6],[7],[8],[9],[10],[11],[12]]\n",
    "activationFunctions = 'relu'\n",
    "epochs = 1\n",
    "##\n",
    "\n",
    "# PCA thetas list\n",
    "# dimSet = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 300, 400]\n",
    "dimSet = [20]\n",
    "\n",
    "for i in range(len(dimSet)):\n",
    "    for j in range(len(nodes)):\n",
    "        # Reduce data with PCA\n",
    "        train_images_red, mean, VRed = nDimPCA(dimSet[i], train_images)\n",
    "        test_images_red = PCAOnTest(VRed, mean, test_images)\n",
    "        #\n",
    "        print(\"PCA dim: \" + str(dimSet[i]))\n",
    "        model = generateModel(nodes[j], activationFunctions, dimSet[i], len(classes))\n",
    "        model = compileModel(model)\n",
    "        trainAccuracy, testAccuracy = trainModel(model, epochs)\n",
    "        #writeToCSV(nodes[j], dimSet[i], activationFunctions, trainAccuracy, testAccuracy, classes)\n",
    "        print(model.summary())\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bf463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T12:32:47.193388Z",
     "start_time": "2022-12-12T12:32:47.193365Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))\n",
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123ea71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T11:28:03.300753Z",
     "start_time": "2022-12-12T11:28:00.443056Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "335.844px",
    "left": "1412px",
    "right": "20px",
    "top": "120px",
    "width": "248px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
